{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e6be24-0cb9-498d-bd42-eac864504702",
   "metadata": {},
   "source": [
    "# Web Content Summarization using Llama3.2-3B (Local Ollama Deployment)\n",
    "\n",
    "## Project Overview\n",
    "This project automates the retrieval and summarization of web content using AI. The system fetches relevant data from:\n",
    "1. **Wikipedia**.\n",
    "2. **2 Top Search Result** â€“ The most relevant webpage from Google Search.\n",
    "\n",
    "The extracted content is summarized using **Llama3.2-3B**, running locally via **Ollama**.\n",
    "\n",
    "## Methodology\n",
    "1. **User Input**: The user provides a topic.\n",
    "2. **Data Retrieval**:\n",
    "   - Wikipedia content is fetched using **BeautifulSoup**.\n",
    "   - The top search result is identified via **Google Search API** and scraped using **Selenium** with Safari WebDriver.\n",
    "3. **Content Processing**:\n",
    "   - Unnecessary elements (scripts, styles, inputs) are removed.\n",
    "   - Wikipedia and the top search result are merged for a comprehensive overview.\n",
    "4. **Summarization**:\n",
    "   - A structured prompt guides the AI.\n",
    "   - **Llama3.2-3B**, running locally on **Ollama**, generates a markdown-formatted summary.\n",
    "5. **Output Display**: The summary is displayed in markdown format.\n",
    "\n",
    "## Features\n",
    "- **Locally hosted AI inference** with **Ollama**, ensuring privacy and performance.\n",
    "- **Multi-source content aggregation** for improved accuracy.\n",
    "- **Automated web scraping** using Wikipedia and Google Search.\n",
    "- **AI-powered structured summaries** with markdown formatting.\n",
    "\n",
    "This system does not make use of any APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d0234-9a81-46a0-9b67-fe8349815cad",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2f1cdc-f656-4d41-8ebf-76a3cf378e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.safari.service import Service\n",
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75e7f2-dee4-4d2a-b4da-bb8a08375b26",
   "metadata": {},
   "source": [
    "## Model using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50003969-8c93-41ef-b7d5-42bf7d9de43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3147c-31e1-4981-92dd-fb6433ec2141",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8264f408-5a06-4534-89cd-f845830b747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_site(query):\n",
    "    \"\"\"Retrieve the top search result URL for a given query.\"\"\"\n",
    "    return next(search(query, num_results=2), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497abe62-6190-4896-9e5e-5d51d665e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_content(url):\n",
    "    \"\"\"Fetch and process webpage content using Safari WebDriver.\"\"\"\n",
    "    driver = webdriver.Safari()\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    \n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "        irrelevant.decompose()\n",
    "    text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "    return title, text\n",
    "\n",
    "def fetch_wikipedia_content(topic):\n",
    "    \"\"\"Fetch Wikipedia page content for a given topic.\"\"\"\n",
    "    url = f\"https://en.wikipedia.org/wiki/{topic.replace(' ', '_')}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return None, None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "        irrelevant.decompose()\n",
    "    text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "    return title, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e07b28-5a67-45e6-9592-83838aa5ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an educational assistant tasked with helping users understand topics \"\n",
    "    \"by providing structured and detailed summaries of web pages. Ignore navigation-related \"\n",
    "    \"text and provide answers in markdown format. The response should include an introduction, \"\n",
    "    \"key points, and a conclusion to make the summary more informative. You are to print everything in english\"\n",
    ")\n",
    "\n",
    "def user_prompt_for(title, text):\n",
    "    \"\"\"Construct a user prompt to generate structured web page summaries.\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    You are reading a web page titled **{title}**.\n",
    "    Below is the combined content extracted from a Wikipedia page and a top search result:\n",
    "\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "\n",
    "    Please summarize this page in markdown format with the following structure:\n",
    "    \n",
    "    # {title}\n",
    "    \n",
    "    ## Introduction\n",
    "    Provide a brief introduction to the topic.\n",
    "    \n",
    "    ## Key Points\n",
    "    Highlight the most important details, covering significant aspects and notable events or concepts.\n",
    "    \n",
    "    ## Conclusion\n",
    "    Summarize the topic concisely and mention its importance or relevance.\n",
    "    \"\"\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c44a56-c618-433d-9151-e75c9e104ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(title, text):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(title, text)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7179e0-5f5b-4d6a-83cc-58fc22a253ad",
   "metadata": {},
   "source": [
    "## Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c308208e-8e9c-4793-a78a-cdf4c9f28f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(topic):\n",
    "    \"\"\"Fetch Wikipedia and top site content, combine them, and generate a structured summary.\"\"\"\n",
    "    wiki_title, wiki_text = fetch_wikipedia_content(topic)\n",
    "    site_url = get_top_site(topic)\n",
    "    site_title, site_text = fetch_page_content(site_url) if site_url else (None, None)\n",
    "    \n",
    "    if not wiki_text and not site_text:\n",
    "        print(\"No suitable content found for this topic.\")\n",
    "        return\n",
    "    \n",
    "    combined_text = \"\\n\\n\".join(filter(None, [wiki_text, site_text]))\n",
    "    final_title = f\"Summary for {topic}\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_for(final_title, combined_text)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d71fcab-d5a4-4a5c-ada6-f17b555ea0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(topic):\n",
    "    \"\"\"Fetch, summarize, and display the Wikipedia and top search result summary.\"\"\"\n",
    "    summary = summarize(topic)\n",
    "    if summary:\n",
    "        display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acea8e63-273e-4676-81f5-6b10e467e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a topic to search and summarize:  LLM\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Summary for LLM\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Large language models (LLMs) are a type of artificial intelligence (AI) designed to process and understand human language. They have become increasingly popular in recent years, revolutionizing various fields such as natural language processing, machine learning, and artificial intelligence.\n",
       "\n",
       "## Key Points\n",
       "\n",
       "### Notable Developments and Advancements\n",
       "\n",
       "*   The first LLM was developed in 2018 by Google's BERT (Bidirectional Encoder Representations from Transformers) team.\n",
       "*   Since then, numerous variants of BERT have been created, including RoBERTa, DistilBERT, and ALBERT.\n",
       "*   Other notable advancements include the introduction of transformer-based models like XLNet, T5, and GPT-1 (also known as GPT).\n",
       "*   Some notable applications of LLMs include:\n",
       "    *   Chatbots and conversational AI\n",
       "    *   Human-computer interaction\n",
       "    *   Sentiment analysis and opinion mining\n",
       "    *   Natural language question answering\n",
       "\n",
       "### Technology and Architecture\n",
       "\n",
       "*   Most modern LLMs are based on transformer architectures, which have shown to be effective for sequential tasks.\n",
       "*   These models often use self-supervised learning approaches to fine-tune their performance.\n",
       "\n",
       "    LLMs can be classified into different types based on:\n",
       "    *   **Training data**:\n",
       "        +   **Supervised**: They receive annotations and labels during training.\n",
       "        +   **Unsupervised**: They do not have annotated labels, relying solely on internal mechanisms.\n",
       "        +   **Self-supervised**: Training data is provided but does not contain direct labels â€” model learns from the environment using external information.\n",
       "\n",
       "    *   **Evaluation criteria**:\n",
       "        +   **Perplexity** \n",
       "        +   **Arousal**\n",
       "    *   **Interpretability models**:\n",
       "        +   Attention mechanisms\n",
       "        +   VQ-VAE\n",
       "\n",
       "### Applications and Impact\n",
       "\n",
       "*   Large language models have shown potential in applications such as customer service chatbots, content generation, natural language processing (NLP), question answering, sentiment analysis, machine learning tasks.\n",
       "\n",
       "    The impact of large language models can be both positive and negative:\n",
       "\n",
       "    **Positive impact**: They can help with:\n",
       "        - Automating various customer support tasks\n",
       "          - Speeding up the process of generating new texts\n",
       "          - Improving the performance in Natural Language Processing (NLP) fields\n",
       "    Negative effects include:\n",
       "    - Job displacement\n",
       "      - The risk of loss in jobs that previously relied on human interaction.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Large language models are transforming various industries with their capabilities and efficiency. They have opened up new avenues for creativity, productivity, and communication but also raised concerns about the potential impact on humans' roles and social behavior when these powerful tools are available throughout society."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = input('Enter a topic to search and summarize: ').strip()\n",
    "display_summary(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ecb491-e22c-4960-b84d-189ca256d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a topic to search and summarize:  NLP\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Summary for NLP\n",
       "\n",
       "## Introduction\n",
       "Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It aims to enable computers to understand, interpret, and generate human-like language.\n",
       "\n",
       "## Key Points\n",
       "* **Key Concepts:\n",
       "\t+ Tokenization: breaking down text into individual words or tokens.\n",
       "\t+ Part-of-speech tagging: identifying the grammatical category of each word (e.g., noun, verb, adjective).\n",
       "\t+ Named entity recognition (NER): identifying specific entities such as names, locations, and organizations.\n",
       "\t+ Sentiment analysis: determining the emotional tone or sentiment behind a piece of text.\n",
       "* ** Techniques:\n",
       "\t+ Machine learning algorithms for NLP tasks.\n",
       "\t+ Deep learning architectures like Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs).\n",
       "\t+ Natural Language Generation (NLG): generating human-like text from structured data.\n",
       "* **Applications:\n",
       "\t+ Chatbots and voice assistants.\n",
       "\t+ Sentiment analysis for social media monitoring.\n",
       "\t+ Machine translation and language understanding.\n",
       "\n",
       "## Conclusion\n",
       "NLP has become a crucial application of AI, enabling computers to understand and interact with humans in natural language. Its applications are vast, ranging from everyday interactions like chatbots to more complex tasks such as sentiment analysis and machine translation. As NLP continues to evolve, we can expect even more sophisticated systems that seamlessly integrate with human communication."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = input('Enter a topic to search and summarize: ').strip()\n",
    "display_summary(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec400cfb-ec3b-4c60-a91a-5499ada1db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a topic to search and summarize:  Transformer attention\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Summary for Transformer Attention\n",
       "\n",
       "## Introduction\n",
       "Transformers are a family of neural network models that utilize self-attention mechanisms to process sequential data. The transformer architecture was introduced in 2017 by Vaswani et al. in a research paper titled \"Attention is All You Need\" and has since become one of the most popular models in deep learning.\n",
       "\n",
       "## Key Points\n",
       "\n",
       "* **Self-Attention Mechanism**: Transformers use self-attention mechanisms to weigh the importance of different input tokens, allowing them to capture long-range dependencies and relationships between different elements.\n",
       "* **Parallel Processing**: Unlike RNNs and LSTMs, which process data sequentially, Transformers process entire sequences simultaneously, making them more efficient for large amounts of data.\n",
       "* **Multi-Head Attention**: The transformer model uses multi-head attention, which allows the model to attend to multiple representations of the input data simultaneously.\n",
       "* **Feed-Forward Neural Networks (FFNNs)**: FFNNs are used in Transformers to transform the output of the self-attention mechanism into a more complex representation that can be processed by the neural network.\n",
       "\n",
       "## Conclusion\n",
       "Transformers have revolutionized the field of natural language processing and computer vision, offering state-of-the-art performance on a wide range of tasks. Their ability to capture long-range dependencies and relationships between input tokens has made them one of the most popular models in deep learning, with applications in image and speech recognition, machine translation, and text generation. As the field continues to evolve, Transformers will likely remain a fundamental component of many computer vision and NLP applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = input('Enter a topic to search and summarize: ').strip()\n",
    "display_summary(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
